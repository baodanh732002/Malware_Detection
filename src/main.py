#!/usr/bin/env python
# coding: utf-8

# In[2]:


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
import seaborn as sns


# In[3]:


data = pd.read_csv('Malware_dataset.csv')


# In[4]:


data.head()


# In[5]:


data = data.drop(columns=['hash'])
data['classification'] = data['classification'].map({'benign': 0, 'malware': 1})


# In[6]:


data.head()


# In[7]:


X = data.drop(columns=['classification'])
Y = data['classification']


# In[8]:


X.head()


# In[9]:


Y.head()


# In[10]:


X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
scaler = MinMaxScaler()
scaler.fit(X_train)


# In[11]:


X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)


# In[12]:


print(pd.DataFrame(X_train_scaled, columns=X.columns).head())


# In[13]:


rf_features = RandomForestRegressor()


# In[14]:


rf_features.fit(X_train_scaled, Y_train)


# In[15]:


rf_features.feature_importances_


# In[16]:


print(X_train.columns)


# In[17]:


feature_names =  X_train.columns


# In[18]:


feature_importances = list(zip(feature_names, rf_features.feature_importances_))
feature_importances_sorted = sorted(feature_importances, key=lambda x: x[1], reverse=True)
for feature, importance in feature_importances_sorted:
    print(f"{feature}: {importance}")


# In[19]:


non_zero_features = [feature for feature, importance in feature_importances_sorted if importance != 0]
print(non_zero_features)


# In[20]:


forest_importances = pd.Series(rf_features.feature_importances_, index=feature_names)
std = np.std([rf_features.feature_importances_ for tree in rf_features.estimators_], axis = 0)


# In[21]:


fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()


# In[22]:


features_selection = non_zero_features
print(features_selection)


# In[24]:


feature_mask = np.isin(X.columns, features_selection)
feature_indices = np.where(feature_mask)[0]


# In[25]:


print(feature_indices)


# In[26]:


X_train_selected = X_train_scaled[:, feature_indices]
X_test_selected = X_test_scaled[:, feature_indices]


# In[27]:


print(X_train_selected)


# In[28]:


print(X_test_selected)


# In[29]:


dt = DecisionTreeClassifier(max_depth=2, min_samples_leaf=1, min_samples_split=2)
dt.fit(X_train_selected, Y_train)
Y_pred_dt = dt.predict(X_test_selected)


# In[30]:


print("Decision Tree:")
print("Confusion Matrix:", confusion_matrix(Y_test, Y_pred_dt))
print("Accuracy:", accuracy_score(Y_test, Y_pred_dt))
print("F1-score:", f1_score(Y_test, Y_pred_dt))
print("Precision:", precision_score(Y_test, Y_pred_dt))
print("Recall:", recall_score(Y_test, Y_pred_dt))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(Y_test, Y_pred_dt), annot=True, fmt="d", cmap="Greens", xticklabels=['Benign', 'Malware'], yticklabels=['Benign', 'Malware'])
plt.title("Confusion Matrix - Decision Tree")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()


# In[31]:


rf = RandomForestClassifier(max_depth=2, min_samples_split=2, n_estimators=10, random_state=42)
rf.fit(X_train_selected, Y_train)
Y_pred_rf = rf.predict(X_test_selected)


# In[32]:


print("Random Forest:")
print("Confusion Matrix:", confusion_matrix(Y_test, Y_pred_rf))
print("Accuracy:", accuracy_score(Y_test, Y_pred_rf))
print("F1-score:", f1_score(Y_test, Y_pred_rf))
print("Precision:", precision_score(Y_test, Y_pred_rf))
print("Recall:", recall_score(Y_test, Y_pred_rf))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(Y_test, Y_pred_rf), annot=True, fmt="d", cmap="Greens", xticklabels=['Benign', 'Malware'], yticklabels=['Benign', 'Malware'])
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()


# In[33]:


nb = MultinomialNB(alpha=10.0, fit_prior=False)
nb.fit(X_train_selected, Y_train)
Y_pred_nb = nb.predict(X_test_selected)


# In[34]:


print("Naive Bayes:")
print("Confusion Matrix:", confusion_matrix(Y_test, Y_pred_nb))
print("Accuracy:", accuracy_score(Y_test, Y_pred_nb))
print("F1-score:", f1_score(Y_test, Y_pred_nb))
print("Precision:", precision_score(Y_test, Y_pred_nb))
print("Recall:", recall_score(Y_test, Y_pred_nb))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(Y_test, Y_pred_nb), annot=True, fmt="d", cmap="Blues", xticklabels=['Benign', 'Malware'], yticklabels=['Benign', 'Malware'])
plt.title("Confusion Matrix - Naive Bayes")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()


# In[35]:


param_grid = {
    'n_estimators': [50, 100, 150],
    'learning_rate': [0.1, 0.5, 1.0],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10]
}

gb = GradientBoostingClassifier()

grid_search = GridSearchCV(
    estimator=gb,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
)

grid_search.fit(X_train_selected, Y_train)


# In[36]:


best_params = grid_search.best_params_
print("Best hyperparameters:", best_params)


# In[38]:


gb = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=150)
gb.fit(X_train_selected, Y_train)
Y_pred_gb = nb.predict(X_test_selected)


# In[39]:


print("Gradient Boosting:")
print("Confusion Matrix:", confusion_matrix(Y_test, Y_pred_gb))
print("Accuracy:", accuracy_score(Y_test, Y_pred_gb))
print("F1-score:", f1_score(Y_test, Y_pred_gb))
print("Precision:", precision_score(Y_test, Y_pred_gb))
print("Recall:", recall_score(Y_test, Y_pred_gb))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(Y_test, Y_pred_gb), annot=True, fmt="d", cmap="Blues", xticklabels=['Benign', 'Malware'], yticklabels=['Benign', 'Malware'])
plt.title("Confusion Matrix - Gradient Boosting")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()


# In[40]:


models = ['Decision Tree', 'Random Forest', 'Naive Bayes', 'Gradient Boosting']
accuracy = [accuracy_score(Y_test, Y_pred_dt), accuracy_score(Y_test, Y_pred_rf), accuracy_score(Y_test, Y_pred_nb), accuracy_score(Y_test, Y_pred_gb)]
f1_scores = [f1_score(Y_test, Y_pred_dt), f1_score(Y_test, Y_pred_rf), f1_score(Y_test, Y_pred_nb), f1_score(Y_test, Y_pred_gb)]
precision = [precision_score(Y_test, Y_pred_dt), precision_score(Y_test, Y_pred_rf), precision_score(Y_test, Y_pred_nb), precision_score(Y_test, Y_pred_gb)]
recall = [recall_score(Y_test, Y_pred_dt), recall_score(Y_test, Y_pred_rf), recall_score(Y_test, Y_pred_nb), recall_score(Y_test, Y_pred_gb)]

x = np.arange(len(models))  # the label locations
width = 0.2  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width*1.5, accuracy, width, label='Accuracy', color='#A7BEA9')
rects2 = ax.bar(x - width/2, f1_scores, width, label='F1-score', color='#84A98C')
rects3 = ax.bar(x + width/2, precision, width, label='Precision', color='#6B917E')
rects4 = ax.bar(x + width*1.5, recall, width, label='Recall', color='#52796F')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Scores')
ax.set_title('Performance of Different Model of Machine Learning')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

fig.tight_layout()

plt.show()

